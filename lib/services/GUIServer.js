const express = require('express')
const http = require('http')
const socketIo = require('socket.io')
const path = require('path')
const chalk = require('chalk')
const AIModelRouter = require('./AIModelRouter')
const LMStudioService = require('./LMStudioService')

/**
 * ğŸ–¥ï¸ mursfoto-cli GUI æœå‹™å™¨
 * æä¾› Web ä»‹é¢ä¾†ç›£æ§ AI æœå‹™ç‹€æ…‹å’Œé…ç½®
 */
class GUIServer {
  constructor(options = {}) {
    this.port = options.port || 12580
    this.host = options.host || 'localhost'
    
    // åˆå§‹åŒ–æœå‹™
    this.app = express()
    this.server = http.createServer(this.app)
    this.io = socketIo(this.server, {
      cors: {
        origin: "*",
        methods: ["GET", "POST"]
      }
    })
    
    // AI æœå‹™
    this.aiRouter = new AIModelRouter()
    this.lmStudioService = new LMStudioService({
      apiEndpoint: process.env.LM_STUDIO_ENDPOINT || 'http://127.0.0.1:1234',
      modelName: process.env.LM_STUDIO_MODEL || 'unsloth/gpt-oss-20b-GGUF'
    })
    
    // ç‹€æ…‹å¿«å–
    this.systemStatus = {
      lastUpdated: null,
      services: {},
      stats: {},
      config: {},
      logs: []
    }
    
    // è¨­ç½®è·¯ç”±å’Œä¸­ä»‹è»Ÿé«”
    this.setupMiddleware()
    this.setupRoutes()
    this.setupSocketHandlers()
    
    // å®šæœŸæ›´æ–°ç‹€æ…‹
    this.startStatusUpdater()
  }
  
  /**
   * ğŸ”§ è¨­ç½®ä¸­ä»‹è»Ÿé«”
   */
  setupMiddleware() {
    // éœæ…‹æª”æ¡ˆæœå‹™
    this.app.use(express.static(path.join(__dirname, '../gui')))
    this.app.use(express.json())
    
    // CORS
    this.app.use((req, res, next) => {
      res.header('Access-Control-Allow-Origin', '*')
      res.header('Access-Control-Allow-Headers', 'Origin, X-Requested-With, Content-Type, Accept')
      next()
    })
  }
  
  /**
   * ğŸ›¤ï¸ è¨­ç½®è·¯ç”±
   */
  setupRoutes() {
    // ä¸»é 
    this.app.get('/', (req, res) => {
      res.sendFile(path.join(__dirname, '../gui/index.html'))
    })
    
    // API è·¯ç”±
    this.app.get('/api/status', async (req, res) => {
      try {
        const status = await this.getSystemStatus()
        res.json(status)
      } catch (error) {
        res.status(500).json({ error: error.message })
      }
    })
    
    this.app.get('/api/services', async (req, res) => {
      try {
        const services = await this.getServicesStatus()
        res.json(services)
      } catch (error) {
        res.status(500).json({ error: error.message })
      }
    })
    
    this.app.get('/api/stats', async (req, res) => {
      try {
        const stats = this.aiRouter.getStats()
        res.json(stats)
      } catch (error) {
        res.status(500).json({ error: error.message })
      }
    })
    
    this.app.get('/api/config', (req, res) => {
      try {
        const config = this.getConfiguration()
        res.json(config)
      } catch (error) {
        res.status(500).json({ error: error.message })
      }
    })
    
    // æ¸¬è©¦ AI æœå‹™
    this.app.post('/api/test/:service', async (req, res) => {
      try {
        const { service } = req.params
        const { prompt } = req.body
        
        const result = await this.testService(service, prompt || 'Hello, æ¸¬è©¦è¨Šæ¯')
        res.json(result)
      } catch (error) {
        res.status(500).json({ error: error.message })
      }
    })
    
    // é‡ç½®çµ±è¨ˆ
    this.app.post('/api/stats/reset', (req, res) => {
      try {
        this.aiRouter.resetStats()
        res.json({ success: true, message: 'çµ±è¨ˆè³‡æ–™å·²é‡ç½®' })
      } catch (error) {
        res.status(500).json({ error: error.message })
      }
    })
  }
  
  /**
   * ğŸ”Œ è¨­ç½® Socket.IO è™•ç†å™¨
   */
  setupSocketHandlers() {
    this.io.on('connection', (socket) => {
      this.logger?.info(chalk.blue('ğŸ”— GUI å®¢æˆ¶ç«¯å·²é€£æ¥'))
      
      // ç™¼é€åˆå§‹ç‹€æ…‹
      socket.emit('system-status', this.systemStatus)
      
      // è™•ç†å®¢æˆ¶ç«¯è«‹æ±‚
      socket.on('request-status', async () => {
        const status = await this.getSystemStatus()
        socket.emit('system-status', status)
      })
      
      socket.on('test-service', async (data) => {
        try {
          const result = await this.testService(data.service, data.prompt)
          socket.emit('test-result', result)
        } catch (error) {
          socket.emit('test-error', { error: error.message })
        }
      })
      
      socket.on('disconnect', () => {
        this.logger?.info(chalk.yellow('ğŸ”Œ GUI å®¢æˆ¶ç«¯å·²æ–·ç·š'))
      })
    })
  }
  
  /**
   * â° é–‹å§‹ç‹€æ…‹æ›´æ–°å™¨
   */
  startStatusUpdater() {
    // æ¯ 5 ç§’æ›´æ–°ä¸€æ¬¡ç‹€æ…‹
    setInterval(async () => {
      try {
        const status = await this.getSystemStatus()
        this.systemStatus = status
        this.io.emit('system-status', status)
      } catch (error) {
        console.error(chalk.red('âŒ ç‹€æ…‹æ›´æ–°å¤±æ•—:'), error.message)
      }
    }, 5000)
    
    // æ¯ 30 ç§’æ›´æ–°ä¸€æ¬¡çµ±è¨ˆè³‡æ–™
    setInterval(() => {
      try {
        const stats = this.aiRouter.getStats()
        this.io.emit('stats-update', stats)
      } catch (error) {
        console.error(chalk.red('âŒ çµ±è¨ˆæ›´æ–°å¤±æ•—:'), error.message)
      }
    }, 30000)
  }
  
  /**
   * ğŸ“Š å–å¾—ç³»çµ±ç‹€æ…‹
   */
  async getSystemStatus() {
    const services = await this.getServicesStatus()
    const stats = this.aiRouter.getStats()
    const config = this.getConfiguration()
    
    return {
      lastUpdated: new Date().toISOString(),
      services,
      stats,
      config,
      system: {
        uptime: process.uptime(),
        memory: process.memoryUsage(),
        platform: process.platform,
        nodeVersion: process.version,
        pid: process.pid
      }
    }
  }
  
  /**
   * ğŸ”§ å–å¾—æœå‹™ç‹€æ…‹
   */
  async getServicesStatus() {
    const services = {}
    
    try {
      // LM Studio ç‹€æ…‹
      services.lmStudio = {
        name: 'LM Studio',
        healthy: await this.aiRouter.isLMStudioHealthy(),
        endpoint: process.env.LM_STUDIO_ENDPOINT || 'http://127.0.0.1:1234',
        model: process.env.LM_STUDIO_MODEL || 'unsloth/gpt-oss-20b-GGUF',
        lastChecked: new Date().toISOString()
      }
      
      // æœ¬åœ°æ¨¡å‹ (Ollama) ç‹€æ…‹
      services.ollama = {
        name: 'Ollama',
        healthy: await this.aiRouter.isLocalModelHealthy(),
        endpoint: 'http://localhost:11434',
        model: 'gpt-oss:20b',
        lastChecked: new Date().toISOString()
      }
      
      // Claude API ç‹€æ…‹
      services.claudeApi = {
        name: 'Claude API',
        healthy: !!process.env.ANTHROPIC_API_KEY,
        endpoint: 'https://api.anthropic.com',
        model: 'claude-3-sonnet-20241022',
        configured: !!process.env.ANTHROPIC_API_KEY,
        lastChecked: new Date().toISOString()
      }
      
      // Cline API ç‹€æ…‹
      services.clineApi = {
        name: 'Cline Claude Code',
        healthy: await this.aiRouter.isClineApiHealthy(),
        endpoint: process.env.CLINE_API_ENDPOINT || 'http://localhost:3001',
        provider: process.env.CLAUDE_CODE_PROVIDER || 'auto',
        lastChecked: new Date().toISOString()
      }
      
    } catch (error) {
      console.error('å–å¾—æœå‹™ç‹€æ…‹æ™‚å‡ºéŒ¯:', error.message)
    }
    
    return services
  }
  
  /**
   * âš™ï¸ å–å¾—é…ç½®è³‡è¨Š
   */
  getConfiguration() {
    return {
      environment: {
        NODE_ENV: process.env.NODE_ENV || 'development',
        ANTHROPIC_API_KEY: process.env.ANTHROPIC_API_KEY ? 'å·²é…ç½®' : 'æœªé…ç½®',
        LM_STUDIO_ENDPOINT: process.env.LM_STUDIO_ENDPOINT || 'http://127.0.0.1:1234',
        LM_STUDIO_MODEL: process.env.LM_STUDIO_MODEL || 'unsloth/gpt-oss-20b-GGUF',
        CLAUDE_CODE_PROVIDER: process.env.CLAUDE_CODE_PROVIDER || 'auto',
        CLINE_API_ENDPOINT: process.env.CLINE_API_ENDPOINT || 'http://localhost:3001'
      },
      aiRouter: {
        defaultTimeout: this.aiRouter.defaultTimeout,
        localModelName: this.aiRouter.localModelName
      },
      gui: {
        port: this.port,
        host: this.host
      }
    }
  }
  
  /**
   * ğŸ§ª æ¸¬è©¦æœå‹™
   */
  async testService(service, prompt) {
    const startTime = Date.now()
    
    try {
      let result
      
      switch (service) {
        case 'lmstudio':
          result = await this.lmStudioService.generate(prompt)
          break
        case 'ollama':
          result = await this.aiRouter.generateWithLocalModel(prompt)
          break
        case 'claude':
          result = await this.aiRouter.generateWithClaudeApi(prompt)
          break
        case 'cline':
          result = await this.aiRouter.generateWithClineApi(prompt)
          break
        case 'auto':
          result = await this.aiRouter.generate(prompt)
          break
        default:
          throw new Error(`ä¸æ”¯æ´çš„æœå‹™: ${service}`)
      }
      
      return {
        success: true,
        service,
        prompt,
        result: result.content,
        responseTime: Date.now() - startTime,
        method: result.metadata?.method || service,
        model: result.model || 'unknown',
        timestamp: new Date().toISOString()
      }
      
    } catch (error) {
      return {
        success: false,
        service,
        prompt,
        error: error.message,
        responseTime: Date.now() - startTime,
        timestamp: new Date().toISOString()
      }
    }
  }
  
  /**
   * ğŸš€ å•Ÿå‹•æœå‹™å™¨
   */
  async start() {
    return new Promise((resolve, reject) => {
      this.server.listen(this.port, this.host, (err) => {
        if (err) {
          reject(err)
        } else {
          this.logger?.info(chalk.green(`\nğŸ–¥ï¸  mursfoto-cli GUI æœå‹™å™¨å·²å•Ÿå‹•`))
          this.logger?.info(chalk.cyan(`ğŸŒ è¨ªå•: http://${this.host}:${this.port}`))
          this.logger?.info(chalk.yellow(`ğŸ“Š å³æ™‚ç›£æ§æ‰€æœ‰ AI æœå‹™ç‹€æ…‹`))
          resolve()
        }
      })
    })
  }
  
  /**
   * ğŸ›‘ åœæ­¢æœå‹™å™¨
   */
  async stop() {
    return new Promise((resolve) => {
      this.server.close(() => {
        this.logger?.info(chalk.yellow('ğŸ›‘ GUI æœå‹™å™¨å·²åœæ­¢'))
        resolve()
      })
    })
  }
}

module.exports = GUIServer
